---
title: "Cross Validation Selection"

---
# Load the data
## Function definition and implementation
```{r}
# Libraries for data manipulation
library(caret)
library(dplyr)
library(caTools)
library(DMwR)
library(e1071)
library(parallel)

# Function to retrieve the data
get_data <- function(drug_reviews, sentiment_rds) {
    # Read the data
    rds <- readRDS(sentiment_rds)
    ge <- read.csv(drug_reviews)
    # Merge the data
    data <- cbind(ge, rds)
    # Return the data
    return(data)
}

# Function to return data with only 'Birth Control' reviews
filter_birth_control <- function(data) {
    data <- data[data$condition == "Birth Control", ]
    return(data)
}

# Function to remove columns
remove_columns <- function(data) {
    data <- select(data, 1, -2:-4, 5:ncol(data))
    return(data)
}

# Function to format the data types
format_dtypes <- function(data) {
    data$rating_type <- as.factor(data$rating_type)
    data <- data %>% mutate_if(is.integer, as.numeric)
    return(data)
}

# Function to filter out bad values
filter_out_bad_vals <- function(data) {
    bad_rows <- apply(
        data, 1,
        function(x) any(is.na(x)) | any(is.nan(x)) | any(is.infinite(x))
    )
    clean_df <- data[!bad_rows, ]
    return(clean_df)
}

# Function to split the data
split_data <- function(data, split_ratio = 0.7, stratified = TRUE) {
    # TODO: Generalise target variable
    if (stratified) {
        # Split with createDataPartition function
        indexes <- createDataPartition(
            data$rating_type,
            p = split_ratio,
            list = FALSE,
            times = 1
        )
        train_data <- data[indexes, ]
        test_data <- data[-indexes, ]
        return(list(train_data, test_data))
    }

    # Split randomly
    if(is.null(data)) {
        stop("The dataframe is empty.")
    }
    tot_rows <- nrow(data)
    indexes <- sample(1:tot_rows, size = 0.8 * nrow(data))
    train_data <- data[indexes, ]
    test_data <- data[-indexes, ]
    return(list(train_data, test_data))
}


# Function to scale and center the data
scale_and_center <- function(train_test) {
    train_data <- train_test[[1]]
    test_data <- train_test[[2]]

    print(head(train))
    preprocess <- preProcess(train_data[, -1], method = c("center", "scale"))
    train[, -1] <- predict(preprocess, train[, -1])
    test[, -1] <- predict(preprocess, test[, -1])
    return(list(train_data, test_data))
}

# Function to perform SMOTE on the data
smote <- function(train_test, perc_over = 100, k = 5) {
    train_data <- train_test[[1]]
    test_data <- train_test[[2]]
    train_data <- SMOTE(
        rating_type ~ .,
        data = train_data,
        perc.over = perc_over,
        k = k
    )
    return(list(train_data, test_data))
}

```

# Cross-Validation methods
- Holdout Cross-Validation
- K-fold Cross-Validation
- Stratified K-fold Cross-Validation
- Repeating K-fold Cross-Validation
- Leave One Out Cross-Validation

## Function definition and implementation

### Cross validation implementation functions
imput -> train_test
- k_fold_cv
- stratified_k_fold_cv
- repeating_k_fold_cv
- leave_one_out_cv
```{r}

# Function to perform unstratifed k-fold cross-validation
k_fold_cv <- function(train_test, k = 10, parallel = FALSE) {
    control <- trainControl(
        method = "cv",
        number = k,
        classProbs = FALSE,
        allowParallel = parallel
    )
    return(control)
}

# Function to perform stratified k-fold cross-validation
stratified_k_fold_cv <- function(train_test,
                                 k = 10,
                                 parallel = FALSE) {
    control <- trainControl(
        method = "cv",
        number = k,
        classProbs = TRUE,
        allowParallel = parallel
    )
    return(control)
}

# Function to perform repeating k-fold cross-validation
repeated_k_fold_cv <- function(train_test,
                                k = 10,
                                parallel = FALSE) {
    control <- trainControl(
        method = "repeatedcv",
        number = k,
        repeats = 3,
        classProbs = TRUE,
        allowParallel = parallel
    )
    return(control)
}

# Function to perform holdout cross-validation
leave_one_out_cv <- function(train_test, parallel = FALSE) {
    control <- trainControl(method = "LOOCV", allowParallel = parallel)
    return(control)
}
```

### Model training functions
imput -> control 
- train_model
```{r}
# Function to train a model with cross validation
train_model <- function(control,
                        train_test,
                        method = "svmLinear",
                        preProcess = c(),
                        verbose = FALSE) {
    train_data <- train_test[[1]]
    model <- train(
        rating_type ~ .,
        data = train_data,
        method = method,
        trControl = control,
        preProcess = preProcess
    )
    if (verbose) {
        print(model)
    }
    return(model)
}
```

### Model evaluation functions
- evaluate_model
```{r}
# Function to evaluate the model
evaluate_model <- function(model, train_test) {
    test_data <- train_test[[2]]
    predictions <- predict(model, test_data)

    confusion_matrix <- confusionMatrix(predictions, test_data$rating_type)
    accuracy <- confusion_matrix$overall[1]
    precision <- confusion_matrix$byClass[1]
    recall <- confusion_matrix$byClass[2]
    f1_score <- 2 * (precision * recall) / (precision + recall)

    return(list(
        accuracy = accuracy,
        precision = precision,
        recall = recall,
        f1_score = f1_score
    ))
}
```

### Model capturing functions
- append_results
```{r}
# Function to get values from list and append it to a dataframe for plotting
append_results <- function(list, df, model_name, cv_name) {
    list$model_name <- model_name
    list$cv_name <- cv_name
    row <- as.data.frame(list, stringsAsFactors = FALSE)
    df <- rbind(df, row)
    return(df)
}
```

# Run Tests
## Data Loading
```{r}
# Load the data and perform some preprocessing
data <- get_data("processed/drug_reviews_ge.csv", "processed/vdf.rds") %>%
    filter_birth_control() %>%
    remove_columns() %>%
    format_dtypes() %>%
    filter_out_bad_vals()

# Split the data into train and test
train_test <- data %>% split_data()

# Results dataframe
pre <- c("center", "scale")
```
## Run cross-validation tests
```{r}
set.seed(0)
results_df
results_df <- NULL

# Run tests
# Time the execution of the tests

print("K-Fold Cross-Validation")
system.time(
results_df <- train_test %>%
    k_fold_cv(k = 10) %>%
    train_model(train_test, preProcess = pre) %>%
    evaluate_model(train_test) %>%
    append_results(results_df, "svmLinear", "k_fold")
)

print("Stratified K-Fold Cross-Validation")
system.time(
results_df <- train_test %>%
    stratified_k_fold_cv(k = 10) %>%
    train_model(train_test, preProcess = pre) %>%
    evaluate_model(train_test) %>%
    append_results(results_df, "svmLinear", "stratified_k_fold")
)

print("Repeated K-Fold Cross-Validation")
system.time(
results_df <- train_test %>%
    repeated_k_fold_cv(k = 10) %>%
    train_model(train_test, preProcess = pre) %>%
    evaluate_model(train_test) %>%
    append_results(results_df, "svmLinear", "repeating_k_fold")
)
# Print the results
results_df
```
```{r, eval=FALSE}
print("Leave One Out Cross-Validation")
train_test %>%
    leave_one_out_cv() %>%
    train_model(train_test, preProcess = pre) %>%
    evaluate_model(train_test) %>%
    append_results(results_df, "svmLinear", "leave_one_out")
```
